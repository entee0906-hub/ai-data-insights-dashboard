{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13103068,"sourceType":"datasetVersion","datasetId":8300135}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T23:35:03.556169Z","iopub.execute_input":"2025-09-18T23:35:03.557105Z","iopub.status.idle":"2025-09-18T23:35:03.572855Z","shell.execute_reply.started":"2025-09-18T23:35:03.557043Z","shell.execute_reply":"2025-09-18T23:35:03.572030Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sample/sample - Sheet1.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# AI Data Insights Dashboard\nThis notebook demonstrates a simple project combining **data analysis** with **AI-generated insights**.\n- Reads a CSV dataset\n- Computes basic statistics\n- Uses OpenAI API to provide natural-language insights and recommendations\n","metadata":{}},{"cell_type":"markdown","source":"Imports, API Key, and Data Load","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport openai\nfrom kaggle_secrets import UserSecretsClient\n\n# Set OpenAI API key\nuser_secrets = UserSecretsClient()\nopenai.api_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\n# Load CSV dataset\ndf = pd.read_csv(\"/kaggle/input/sample/sample - Sheet1.csv\")\n\n# Quick check\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T23:35:03.574480Z","iopub.execute_input":"2025-09-18T23:35:03.575036Z","iopub.status.idle":"2025-09-18T23:35:03.728222Z","shell.execute_reply.started":"2025-09-18T23:35:03.575012Z","shell.execute_reply":"2025-09-18T23:35:03.727152Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   id      category  value        date   location\n0   1         Noise      3  2025-01-05   Brooklyn\n1   2      Delivery      5  2025-01-06  Manhattan\n2   3         Noise      2  2025-01-07     Queens\n3   4  CustomerCare      4  2025-01-08   Brooklyn\n4   5      Delivery      3  2025-01-09      Bronx","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>category</th>\n      <th>value</th>\n      <th>date</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Noise</td>\n      <td>3</td>\n      <td>2025-01-05</td>\n      <td>Brooklyn</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Delivery</td>\n      <td>5</td>\n      <td>2025-01-06</td>\n      <td>Manhattan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Noise</td>\n      <td>2</td>\n      <td>2025-01-07</td>\n      <td>Queens</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>CustomerCare</td>\n      <td>4</td>\n      <td>2025-01-08</td>\n      <td>Brooklyn</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Delivery</td>\n      <td>3</td>\n      <td>2025-01-09</td>\n      <td>Bronx</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"Basic Analysis Function","metadata":{}},{"cell_type":"code","source":"# Cell 2: Basic Analysis\ndef basic_analysis(df):\n    analysis = {}\n    analysis[\"num_rows\"] = len(df)\n    analysis[\"num_columns\"] = len(df.columns)\n    analysis[\"column_names\"] = df.columns.tolist()\n\n    numeric_stats = df.describe(include=\"number\").to_dict()\n    analysis[\"numeric_summary\"] = numeric_stats\n\n    categorical_stats = {}\n    for col in df.select_dtypes(include=\"object\"):\n        top_value = df[col].mode().iloc[0] if not df[col].mode().empty else None\n        categorical_stats[col] = str(top_value)\n    analysis[\"categorical_summary\"] = categorical_stats\n\n    return analysis\n\n# Run basic analysis\nsummary = basic_analysis(df)\n\nprint(\"ðŸ“Š BASIC ANALYSIS\")\nfor key, value in summary.items():\n    print(f\"- {key}: {value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T23:35:03.729370Z","iopub.execute_input":"2025-09-18T23:35:03.729674Z","iopub.status.idle":"2025-09-18T23:35:03.743431Z","shell.execute_reply.started":"2025-09-18T23:35:03.729650Z","shell.execute_reply":"2025-09-18T23:35:03.742484Z"}},"outputs":[{"name":"stdout","text":"ðŸ“Š BASIC ANALYSIS\n- num_rows: 8\n- num_columns: 5\n- column_names: ['id', 'category', 'value', 'date', 'location']\n- numeric_summary: {'id': {'count': 8.0, 'mean': 4.5, 'std': 2.449489742783178, 'min': 1.0, '25%': 2.75, '50%': 4.5, '75%': 6.25, 'max': 8.0}, 'value': {'count': 8.0, 'mean': 3.5, 'std': 1.1952286093343936, 'min': 2.0, '25%': 2.75, '50%': 3.5, '75%': 4.25, 'max': 5.0}}\n- categorical_summary: {'category': 'Delivery', 'date': '2025-01-05', 'location': 'Brooklyn'}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Cell 3: AI Insights\ndef ai_insights(summary):\n    prompt = f\"\"\"\n    Here is a summary of a dataset:\n    {summary}\n\n    Please:\n    1. Explain the dataset in plain English.\n    2. Highlight one interesting trend or pattern.\n    3. Suggest two recommendations someone could act on.\n    \"\"\"\n    \n    response = openai.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.6,\n        max_tokens=250\n    )\n    \n    return response.choices[0].message.content\n\n# Run AI insights\nprint(\"\\nðŸ¤– AI INSIGHTS\")\nai_result = ai_insights(summary)\nprint(ai_result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T23:36:01.149935Z","iopub.execute_input":"2025-09-18T23:36:01.150604Z","iopub.status.idle":"2025-09-18T23:36:03.752796Z","shell.execute_reply.started":"2025-09-18T23:36:01.150570Z","shell.execute_reply":"2025-09-18T23:36:03.751454Z"}},"outputs":[{"name":"stdout","text":"\nðŸ¤– AI INSIGHTS\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_106/2298735881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run AI insights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ¤– AI INSIGHTS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mai_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai_insights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_106/2298735881.py\u001b[0m in \u001b[0;36mai_insights\u001b[0;34m(summary)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     response = openai.chat.completions.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"],"ename":"RateLimitError","evalue":"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"# Mocked AI result for demonstration\nai_result = \"\"\"\nThe dataset contains 8 rows and 5 columns with information about deliveries.\nOne interesting trend is that all deliveries occurred in Brooklyn on the same date.\nRecommendations:\n1. Track deliveries over multiple dates to find patterns in demand.\n2. Analyze values by category to optimize delivery scheduling.\n\"\"\"\nprint(ai_result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T23:37:32.195368Z","iopub.execute_input":"2025-09-18T23:37:32.195707Z","iopub.status.idle":"2025-09-18T23:37:32.200563Z","shell.execute_reply.started":"2025-09-18T23:37:32.195683Z","shell.execute_reply":"2025-09-18T23:37:32.199732Z"}},"outputs":[{"name":"stdout","text":"\nThe dataset contains 8 rows and 5 columns with information about deliveries.\nOne interesting trend is that all deliveries occurred in Brooklyn on the same date.\nRecommendations:\n1. Track deliveries over multiple dates to find patterns in demand.\n2. Analyze values by category to optimize delivery scheduling.\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Summary\n- This notebook demonstrates how to combine **data analytics** and **AI APIs**.\n- Shows basic statistics and generates natural-language insights automatically.\n- Ready to be extended to larger datasets or other applications.\n","metadata":{}}]}